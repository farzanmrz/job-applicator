Step 1 is to build the Core Preference Model. This involves creating a canonical schema that represents all job preferences using standardized category names like employment_type, location_type, and experience_level, along with their corresponding standardized values such as full_time, part_time, remote, on_site, etc. You should also design this schema to support mappings from synonymous terms (e.g., “Permanent” or “Full Time” both map to full_time). This module should allow adding new categories or values over time and return canonical values when given variants. Once implemented, test this module by feeding it common job terms from different portals and confirming it correctly returns canonical categories and values.

Step 2 is to implement the LinkedIn Adapter module. This adapter uses the Core Preference Model to translate internal preference categories and values into LinkedIn’s specific terminology and interface elements. It needs to know where each filter appears in the LinkedIn UI (e.g., in a popup modal or sidebar), how to interact with those elements (e.g., select dropdowns, checkboxes), and how to apply a given preference value to the right place on the page. The adapter should be designed to fetch the current state of LinkedIn's job preference UI and apply mappings using the canonical preference model. Test this by manually logging into LinkedIn, having the system read stored preferences, and check if it correctly applies them through the UI.

Step 3 is to build fallback handling in the LinkedIn Adapter. When LinkedIn’s UI contains a field or option that doesn’t match any internal preference confidently, the adapter should log it along with the related portal term and the user’s stored preference category. It should then prompt the user to either map the unknown field/option to an existing internal value or create a new preference category or value in the core model. The focus here is on gracefully handling partial matches and building robustness. You can test this by intentionally inserting a new LinkedIn filter or simulating an unknown value and checking if the system prompts for resolution properly.

Step 4 is to implement the General Matching Agent for new job portals. This agent should use semantic matching techniques (like text embeddings) to compare portal filter labels and values to those in the Core Preference Model, especially when encountering unfamiliar terms or UI layouts. It should also recognize common UI filter types like dropdowns and checkboxes to identify where and how to apply mapped preferences. This module maintains a confidence score for each match and can flag low-confidence cases for manual review. You should test it first using mock HTML from unfamiliar job portals and check whether matches are accurate and confidence scores behave as expected.

Step 5 is to create a memory and learning layer for unmatched terms. This step ensures that any new field or value encountered—whether during LinkedIn use or general portal crawling—is stored in a growing dictionary. If the user maps an unknown term to a known one, that association is saved permanently. This helps the agent become smarter over time and reduce future ambiguity. You can test this by feeding it several new variations of known terms, correcting them manually, and checking whether future encounters are auto-mapped correctly.

Step 6 is to design inter-module interfaces. Since this system is part of a multi-agent architecture, each module—the Core Model, LinkedIn Adapter, and General Matching Agent—needs a defined interface to communicate. This includes defining request-response formats, how preference data is exchanged, and how fallback decisions are passed to the user interface or other agents. Once you define these, test by simulating end-to-end preference application across modules for a complete user job search session.

Step 7 is to create a unified orchestration layer. This layer coordinates the entire flow: loading user preferences, selecting the right platform module, applying preferences, handling mismatches, and learning new mappings. It should act as the controller or master agent that triggers the others in the right order. Testing here involves full-system dry runs where you simulate a user trying to apply preferences on LinkedIn and another unfamiliar site, confirming whether each step is correctly handled through the pipeline.

Step 8 is to refine and productionize the LinkedIn module first. Since this is your initial focus, freeze the LinkedIn Adapter after testing and wrap it in a CLI or interface for your job-search pipeline. Ensure it works consistently with the current version of LinkedIn and can be reused or extended if the UI changes slightly. Once it is stable and testable end-to-end with preference inputs, you can move to generalize for other platforms confidently.